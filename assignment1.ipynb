{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gzip\n","from collections import defaultdict\n","import math\n","import scipy.optimize\n","from sklearn import svm\n","import numpy\n","import string\n","import random\n","import string\n","from sklearn import linear_model\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","import lightgbm as ltb\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def readGz(path):\n","  for l in gzip.open(path, 'rt'):\n","    yield eval(l)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def readCSV(path):\n","  f = gzip.open(path, 'rt')\n","  f.readline()\n","  for l in f:\n","    yield l.strip().split(',')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def accuracy(pred, y):\n","    return sum([x==y for x,y in zip(pred, y)]) / len(pred)\n","def Jaccard(s1, s2):\n","    numer = len(s1.intersection(s2))\n","    denom = len(s1.union(s2))\n","    if denom == 0:\n","        return 0\n","    return numer / denom"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["allRatings = []\n","for l in readCSV(\"train_Interactions.csv.gz\"):\n","    allRatings.append(l)"]},{"cell_type":"markdown","metadata":{},"source":["## Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ratingsTrain = allRatings[:180000]\n","ratingsValid = allRatings[180000:]\n","ratingsPerUser = defaultdict(list)\n","ratingsPerItem = defaultdict(list)\n","for u,b,r in ratingsTrain:\n","    ratingsPerUser[u].append((b,r))\n","    ratingsPerItem[b].append((u,r))\n","len(allRatings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bookCount = defaultdict(int)\n","totalRead = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n","  bookCount[book] += 1\n","  totalRead += 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mostPopular = [(bookCount[x], x) for x in bookCount]\n","mostPopular.sort()\n","mostPopular.reverse()"]},{"cell_type":"markdown","metadata":{},"source":["calculate most popular books"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["return1 = set()\n","count = 0\n","for ic, i in mostPopular:\n","  count += ic\n","  return1.add(i)\n","  if count > totalRead/2: break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["totalbook = set()\n","data_ub = []\n","booksPerUser = defaultdict(set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for u,b,r in ratingsTrain:\n","    totalbook.add(b)\n","    booksPerUser[u].add(b)\n","    \n","for u,b,r in ratingsValid:\n","    totalbook.add(b)\n","    data_ub.append((u,b))\n","    booksPerUser[u].add(b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_0 = []\n","for i in data_ub:\n","    u = i[0]\n","    validation_0.append((u, random.sample(totalbook.difference(booksPerUser[u]), 1)))"]},{"cell_type":"markdown","metadata":{},"source":["1 represents read the book"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_set = []\n","for i in data_ub:\n","    validation_set.append([i[0], i[1], 1])\n","for j in validation_0:\n","    validation_set.append([j[0], j[1][0], 0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n","itemsPerUser = defaultdict(set) # Maps a user to the items that they rateduser\n","for u,b,r in ratingsTrain:\n","    usersPerItem[b].add(u)\n","    itemsPerUser[u].add(b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["book_count = {}\n","for ic, i in mostPopular:\n","    book_count[i] = ic\n","avg_count = numpy.mean([i[0] for i in mostPopular])\n","def feature(u,b):\n","    Jaccard_u = []\n","    for b2 in itemsPerUser[u]:\n","        if b2 == b:\n","            continue\n","        Jaccard_u.append(Jaccard(usersPerItem[b2], usersPerItem[b]))\n","    if Jaccard_u == []:\n","        tocompare = 0\n","    else: tocompare = numpy.max(Jaccard_u)\n","    Jaccard_u1 = []\n","    for u2 in usersPerItem[b]:\n","        if u2 == u:\n","            continue\n","        Jaccard_u1.append(Jaccard(itemsPerUser[u2], itemsPerUser[u]))\n","    if Jaccard_u1 == []:\n","        tocompare1 = 0\n","    else: tocompare1 = numpy.max(Jaccard_u1)\n","    book_pop = avg_count\n","    if b in book_count:\n","        book_pop = book_count[b]\n","    return [1, book_pop, tocompare, tocompare1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = [feature(i[0],i[1]) for i in validation_set]\n","y = [i[2] for i in validation_set]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_acc = 0\n","best_model = 0\n","for c in tqdm(range(-10, 10)):\n","    acc_avg = []\n","    acc_max_model = 0\n","    acc_max = 0\n","    for i in range(0,10):\n","        model = linear_model.LogisticRegression(C = 10 ** c, fit_intercept=False)\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n","        model.fit(X_train, y_train)\n","        prediction = model.predict(X_test)\n","        acc = accuracy(prediction, y_test)\n","        acc_avg.append(acc)\n","        if acc > acc_max:\n","            acc_max = acc\n","            acc_max_model = model\n","    acc_avg = numpy.average(numpy.array(acc_avg))\n","    print(acc_avg, c)\n","    if acc_avg > best_acc:\n","        best_model = acc_max_model\n","        best_acc = acc_avg\n","print(best_acc, best_model.coef_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_acc"]},{"cell_type":"markdown","metadata":{},"source":["## Category prediction baseline: Just consider some of the most common words from each category"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["catDict = {\n","  \"children\": 0,\n","  \"comics_graphic\": 1,\n","  \"fantasy_paranormal\": 2,\n","  \"mystery_thriller_crime\": 3,\n","  \"young_adult\": 4\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for d in readGz(\"train_Category.json.gz\"):\n","    data.append(d)"]},{"cell_type":"markdown","metadata":{},"source":["hw3 + distinctive feature for each genre"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["punctuation = set(string.punctuation)\n","dfs = [defaultdict(int), defaultdict(int), defaultdict(int), defaultdict(int), defaultdict(int)]\n","for d in data:\n","    df = dfs[d['genreID']]\n","    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n","    for w in set(r.split()):\n","        df[w] += 1\n","for i in stopwords.words('english'):\n","    for df in dfs:\n","        if i in df:\n","            del df[i]\n","counts = [sorted([(v,k) for k, v in df.items()], reverse=True) for df in dfs]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(counts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["words_cat = [set()] * 5\n","for idx in tqdm(range(5)):\n","    for i in counts[idx][:5000]:\n","        words_cat[idx].add(i[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_five_cat_words = words_cat[0]\n","for i in words_cat:\n","    all_five_cat_words = all_five_cat_words.union(i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wordId = dict(zip(all_five_cat_words, range(len(all_five_cat_words))))\n","wordSet = set(all_five_cat_words)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(wordSet)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_five_cat_words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vectorizer = CountVectorizer()\n","vectorizer.fit_transform(all_five_cat_words)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vectorizer.transform([data[0]['review_text']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def feature_vector(datum):\n","    feat = vectorizer.transform([datum['review_text']]).toarray()\n","    return feat[0]\n","X = [feature_vector(d) for d in data]\n","y = [d['genreID'] for d in data]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Xtrain = numpy.array(X[:8*len(X)//10])\n","ytrain = numpy.array(y[:8*len(y)//10])\n","Xvalid = numpy.array(X[8*len(X)//10:])\n","yvalid = numpy.array(y[8*len(y)//10:])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["lgbm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mod = ltb.LGBMClassifier(num_leaves = 100, n_estimators = 1000, learning_rate = 0.07, reg_alpha = 1, reg_lambda = 0.1, n_jobs = -1,objective = 'multiclass')\n","mod.fit(Xtrain, ytrain)\n","pred = mod.predict(Xvalid)\n","correct = pred == yvalid\n","print(sum(correct) / len(correct))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = open(\"predictions_Category.csv\", 'w')\n","pos = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data = []\n","for l in readGz('test_Category.json.gz'):\n","    test_data.append(l)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for l in open(\"pairs_Category.csv\"):\n","    if l.startswith(\"userID\"):\n","        predictions.write(l)\n","        continue\n","    \n","    x = feature_vector(test_data[pos])\n","    \n","#     prediction = best_model.predict([x])\n","    prediction = mod.predict([x])\n","    print(l[:-1] + \",\" + str(prediction[0]) + \"\\n\")\n","    predictions.write(l[:-1] + \",\" + str(prediction[0]) + \"\\n\")\n","    pos += 1\n","predictions.close()"]},{"cell_type":"markdown","metadata":{},"source":["n_estimator: 1000, learning_rate:0.04 0.7395<br>\n","n_estimator: 1000, learning_rate: 0.07, reg_alpha: 1, reg_lambda = 0.1, acc: 0.7507<br>\n",":3000 len(feature) = 4867"]},{"cell_type":"markdown","metadata":{},"source":["no stem"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_model = 0\n","best_acc = 0\n","for c in tqdm(range(-2, 4)):\n","    mod = linear_model.LogisticRegression(C=10 ** c)\n","    mod.fit(Xtrain, ytrain)\n","    pred = mod.predict(Xvalid)\n","    correct = pred == yvalid\n","    if sum(correct) / len(correct) > best_acc:\n","        best_model = mod\n","        best_acc = sum(correct) / len(correct)\n","    print(c, sum(correct) / len(correct))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('cse151b')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"e5ef2bb8cfce3ef4858e71acbffde9931267c97337c0fccb0d9d393e9561a8d4"}}},"nbformat":4,"nbformat_minor":2}
